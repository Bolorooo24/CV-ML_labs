{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMkN/YAotqB+tQruaVwLwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bolorooo24/CV-ML_labs/blob/main/Pytorch-deep-learning/03_pytorch_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch computer vision\n",
        "* See the reference notebook : https://github.com/mrdbourke/pytorch-deep-learning/blob/main/video_notebooks/03_pytorch_computer_vision_video.ipynb\n",
        "* See reference online book : https://www.learnpytorch.io/03_pytorch_computer_vision/"
      ],
      "metadata": {
        "id": "DplGp_cLko73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Computer vision libraries in Pytorch\n",
        "* 'torchvision' - base domain library for computer vision - https://docs.pytorch.org/vision/main/index.html\n",
        "* 'torchvision.datasets' - get datasets and data loading functions for computer vision\n",
        "* 'torchvision.models' - get pretrained computer vision models that you can apply for your problems\n",
        "* 'torchvision.transforms' - functions for mainpulating your vision data images\n",
        "* 'torch.utils.data.Dataset' - Base dataset class for pytorch\n",
        "* 'torch.utils.data.DataLoader' - Creates a python iterable over a dataset"
      ],
      "metadata": {
        "id": "KHx7hhbvoNQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# visualize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# check versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "aRdxjxIbpQBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting a computer vision dataset\n",
        "\n",
        "FashionMNIST dataset will be used from torchvision.datasets - https://docs.pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST\n"
      ],
      "metadata": {
        "id": "4pYBKhsJp4mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to?\n",
        "    train=True, # do we want the training dataset?\n",
        "    download=True, # do we want to download yes/no?\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None # how do we want to transform the labels/targets?\n",
        "\n",
        ")\n",
        "# setup test data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "fVFUujFxq4LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "de_iRafMrj1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the first trianing example\n",
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "GJNnCWXnsEAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "nlU_8bGVlsP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
      ],
      "metadata": {
        "id": "sNH3w4mjl9je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names= train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "4GtFy6C5sl2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "LIMmw0x7s0TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "F5k4Ud_1s6KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape\n",
        "print(f\"image shape: {image.shape} -> [color_channels, height, width]\")\n",
        "print(f\"image label: {class_names[label]}\")"
      ],
      "metadata": {
        "id": "nYJ5FGSls-Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Visualizing Random samples of data"
      ],
      "metadata": {
        "id": "JZDGOfnUtB0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "jRlFbqpKoE24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label]);\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "JPifj5r5uEGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False);\n"
      ],
      "metadata": {
        "id": "qpuiF12OuNzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "X5Hz0Bmsul32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare DataLoader\n",
        "\n",
        "Right now, out data is in the form of pytorch dataset.\n",
        "DataLoader turns our dataset into a python iterable\n",
        "Specifically, we want to turn our data into batches or mini-batches.\n",
        "\n",
        "1. It is more computationally efficient, as in, your computing hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32)\n",
        "2. It gives our neural network more chances to update its gradients per epoch\n",
        "\n",
        "Andrew ng batch mini size lecure - https://www.youtube.com/watch?v=ed4whd9B-xw"
      ],
      "metadata": {
        "id": "ZcW3M-AawrVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader # https://docs.pytorch.org/docs/stable/data.html\n",
        "\n",
        "# setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# turn dataset into iterables (batches)\n",
        "train_dataloader = DataLoader(dataset=train_data, # dataset to turn into iterable\n",
        "                              batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "                              shuffle=True) # shuffle data every epoch?\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "tUDj9nS5xvmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check out what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Lenght of the train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
        "print(f\"Lenght of the train dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
      ],
      "metadata": {
        "id": "hLcGNu1pzMO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "2c08oG6m0PUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label.shape}\")"
      ],
      "metadata": {
        "id": "ZT3Esb0qz6oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model 0: Creating a baseline model\n",
        "\n",
        "When starting to build a series of machine learning modelling experiments, it's best practice to build baseline model\n",
        "\n",
        "A baseline model is a simple model you will try improve upon with subsequent models/experiments\n",
        "\n",
        "In other words: start simply add complexity when necessary"
      ],
      "metadata": {
        "id": "QGSKRBSq1a3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# get a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# flatten the sample\n",
        "output= flatten_model(x) # perform forward pass\n",
        "\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height* width]\")\n"
      ],
      "metadata": {
        "id": "NZD8HKIF2RDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.squeeze().shape"
      ],
      "metadata": {
        "id": "f6G_8jer2erX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(), # neural networkds like their inputs in vector form\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xe98A0m-mgT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# setup model with input parameters\n",
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape=784, # this is 28*28\n",
        "    hidden_units=10, # how many unit sin the hidden layer\n",
        "    output_shape=len(class_names) # one for every class\n",
        ").to(\"cpu\")\n",
        "model_0"
      ],
      "metadata": {
        "id": "dKrBXJzlq47r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_names)"
      ],
      "metadata": {
        "id": "zDVL1-llsZSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1,1,28,28])\n",
        "model_0(dummy_x).shape"
      ],
      "metadata": {
        "id": "g9ZvmOK6rbYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "AEvuoA-qrsOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Setup a loss and optimizer and evaluation metrics\n",
        "* Loss function - since we're working with multi-class data, our loss function will eb 'nn.CrossEntropyLoss()'\n",
        "* Optimizer - our optimizer 'torch_optim.SDG' (stochastic gradient descent)\n",
        "* Evaluation metric - since we're working on a classification problem, let's use accuracy as our evaluation metric\n"
      ],
      "metadata": {
        "id": "hPf8PPIgsmmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# download helper functions from learn pytorch repo\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "uQAIW7mYtVQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import accuracy metric\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)\n"
      ],
      "metadata": {
        "id": "JNkxxOKKuF7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Creating a function to time our experiments\n",
        "\n",
        "Machine learning is very experimental.\n",
        "\n",
        "Two of the main things you'll often want to track are:\n",
        "1. Model's performance (loss and accuracy values etc)\n",
        "2. How fast it runs\n",
        "\n"
      ],
      "metadata": {
        "id": "R6-jVpXBHcwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device=None):\n",
        "  \"\"\"Prints difference between start and end time\n",
        "  \"\"\"\n",
        "  total_time = end-start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "\n",
        "  return total_time\n"
      ],
      "metadata": {
        "id": "W95B_9klIO0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer()\n",
        "\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time,\n",
        "                 end=end_time,\n",
        "                 device=\"cpu\")"
      ],
      "metadata": {
        "id": "aD0C2LKbIsgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data\n",
        "\n",
        "1. Loop through epochs,\n",
        "2. Loop through training batches, perform training steps, calculate the train loss *per batch*\n",
        "3. Loop through testing batches, perform testing steps, calculate the test loss per batch\n",
        "4. Print out what's happening\n",
        "5. Time it all for fun\n"
      ],
      "metadata": {
        "id": "puWR4dVyI4Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tqdm from progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# set the seed and start the timer\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# set the number of epochs\n",
        "epochs =3\n",
        "\n",
        "# create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-----\")\n",
        "\n",
        "  ###training\n",
        "  train_loss=0\n",
        "  # add a loop to loop through the training batches\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # 1. Forward pass\n",
        "    y_pred=model_0(X)\n",
        "\n",
        "    # 2. Calculate loss (per batch)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss # accumulate train loss\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # print out\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"lOoked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
        "  # divide total train loss by length of train dataloader\n",
        "  train_loss/=len(train_dataloader)\n",
        "\n",
        "  ### testing\n",
        "  test_loss, test_acc = 0,0\n",
        "  model_0.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      # 1. Forward pass\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. Calculate loss (accumulativeluy)\n",
        "      test_loss += loss_fn(test_pred, y_test).item()\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y_test,\n",
        "                              y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # calculate the test acc average per batch\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
        "# calcualte training time\n",
        "train_time_end_on_cpu=timer()\n",
        "total_train_time_model_0 = print_train_time(\n",
        "    start=train_time_start_on_cpu,\n",
        "    end=train_time_end_on_cpu,\n",
        "    device=str(next(model_0.parameters()).device))\n",
        "\n"
      ],
      "metadata": {
        "id": "6i-NhU5zJQAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Make predictions and get model0 results\n"
      ],
      "metadata": {
        "id": "mYhMr5FyOCxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "  \"\"\"Returns a dictionary containing the results of model predicting on data_loader\"\"\"\n",
        "  loss, acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "      # make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # accumulate the loss and acc values per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y,\n",
        "                         y_pred = y_pred.argmax(dim=1))\n",
        "    # scalre loss and acc to find the avg loss/acc per batch\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "  return {\"model_name\": model.__class__.__name__, # only works when model was created with class\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc\n",
        "          }\n",
        "\n",
        "# calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "\n",
        "model_0_results\n"
      ],
      "metadata": {
        "id": "Q_AZS3o0oxMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results = eval_model(model=model_0,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn = loss_fn,\n",
        "                             accuracy_fn=accuracy_fn\n",
        "                             )\n",
        "\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "D_FW2mz_21eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "IzfQ1sWxrdhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Setup device agnostic-code (for using a GPU if there is one)"
      ],
      "metadata": {
        "id": "BimAmeZ3rkCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "hzFl2HQlqaq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model 1: Create non-linear model\n",
        "\n",
        "We learned the non linear model in model 2."
      ],
      "metadata": {
        "id": "I53gAJbxrwjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.linear import Linear\n",
        "import torch.nn as nn\n",
        "# create a model\n",
        "\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self, input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "\n",
        "    )\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.layer_stack(x)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5-L5uEkur5Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an isntance of model_1\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = FashionMNISTModelV1(\n",
        "    input_shape=784, # this 28*28\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ").to(device)\n",
        "\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "Nec2_qLAwBzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Setup loss, optimizer and evaluation metrics\n"
      ],
      "metadata": {
        "id": "UeiP1Jz1yWSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "# create loss function and optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() # measure how wrong our mdoel is\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), # tries to update our mdoel;s parameters to reduce the loss\n",
        "                            lr = 0.1)\n"
      ],
      "metadata": {
        "id": "PAI2xCRAxtma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Functionizing training and evaluation loop\n",
        "\n",
        "Let's create a function for:\n",
        " * training loop : train_step()\n",
        " * test loop : test_step()"
      ],
      "metadata": {
        "id": "gk6NNPiHy8eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               model: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device=device\n",
        "               ):\n",
        "\n",
        "  \"\"\"Performs a training with model trying to learn on data_loader\"\"\"\n",
        "\n",
        "  train_loss, train_acc = 0,0\n",
        "\n",
        "  # put model into trianing mode\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    # put data on target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # 2. Calculate loss (per batch)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss # accumulatively add up the loss per epoch\n",
        "    train_acc += accuracy_fn(y_true=y,\n",
        "                             y_pred=y_pred.argmax(dim=1)) # go from logits to prediction label\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out how many samples have been seen\n",
        "    if batch % 400 == 0:\n",
        "        print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W-_2QIuNyQYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              accuracy_fn,\n",
        "              device: torch.device=device):\n",
        "  \"\"\"Performs a testing loop step on model going over data_loader.\"\"\"\n",
        "  test_loss, test_acc = 0, 0\n",
        "  # put the model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # turn on inference mode context manager\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "      # send the data to the target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred = model(X)\n",
        "\n",
        "      # 2. Calculate loss (accumulatively)\n",
        "      test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "      # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "      test_acc += accuracy_fn(y_true=y,\n",
        "                              y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "    # Divide total test loss by length of test dataloader (per batch)\n",
        "    test_loss /= len(data_loader)\n",
        "\n",
        "    # Divide total accuracy by length of test dataloader (per batch)\n",
        "    test_acc /= len(data_loader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jDHBbkXr1n1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "# set the random seed\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n--------\")\n",
        "  train_step(data_loader=train_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             model=model_1,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device\n",
        "             )\n",
        "  test_step(model=model_1,\n",
        "            loss_fn=loss_fn,\n",
        "            data_loader=test_dataloader,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device)\n",
        "\n",
        "  train_time_end_on_gpu = timer()\n",
        "  total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
        "                                              end=train_time_end_on_gpu,\n",
        "                                              device=device)"
      ],
      "metadata": {
        "id": "b12WLcFV4FMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "zGGU36dYyS5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note** Sometimes, depending on your data/hardware you might find that your model trains faster on cpu and gpu.\n",
        ">\n",
        "> Why is this?\n",
        "> 1. It could be that the overhead for copying data/model to and from the pug outweghts the compute benefits offered by the gpu\n",
        "> 2. The hardware you're using has a better cpu in terms compute capability than the gpu\n",
        "\n",
        "Read more here: https://horace.io/brrr_intro.html"
      ],
      "metadata": {
        "id": "JpZy4E3U0RCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device=device):\n",
        "  \"\"\"Returns a dictionary containing the results of model predicting on data_loader\"\"\"\n",
        "  loss, acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "      # make our data device agnostic\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # accumulate the loss and acc values per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y,\n",
        "                         y_pred = y_pred.argmax(dim=1))\n",
        "    # scalre loss and acc to find the avg loss/acc per batch\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "  return {\"model_name\": model.__class__.__name__, # only works when model was created with class\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc\n",
        "          }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n3jUqBwU3H-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get mode_1 results dictionary\n",
        "model_1_results = eval_model(model=model_1,\n",
        "                             data_loader=test_dataloader,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             loss_fn=loss_fn,\n",
        "                             device=device)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "b5nE2m9C0yAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "VaT7ljlI1ksN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Building a convolutional neural network\n",
        "\n",
        "CNN's are also know as ConvNets.\n",
        "\n",
        "CNN's are known for their capabilities to find patterns in visual data\n",
        "\n",
        "cnn explainer: https://poloclub.github.io/cnn-explainer/"
      ],
      "metadata": {
        "id": "WWW2JMkQ3ckE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "from torch.nn.modules.conv import Conv2d\n",
        "from torch.nn.modules import padding\n",
        "# create a convolutional neural network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture that replicates the TinyVGG\n",
        "  model from CNN explainer website\n",
        "  \"\"\"\n",
        "  def __init__(self,input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    # create\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1), # values we can set ourselves in our NN's are called hyperparameters\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(f\"Output shape of conv_block_1 : {x.shape}\")\n",
        "    x = self.conv_block_2(x)\n",
        "    #  print(f\"Output shape of conv_block_2 : {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    # print(f\"Output shape of classifier : {x.shape}\")\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "SRvqxRzB3wsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)\n",
        "model_2"
      ],
      "metadata": {
        "id": "sClAhRMm9rdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Stepping thtough 'nn.Conv2d()'\n",
        "See the documentation here - https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
      ],
      "metadata": {
        "id": "jRckBQDmYs2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# create a batch of images\n",
        "images = torch.randn(size=(32,3,64,64))\n",
        "test_image = images[0]\n",
        "\n",
        "print(f\"Image batch shape: {image.shape}\")\n",
        "print(f\"Singe image shape: {test_image.shape}\")\n"
      ],
      "metadata": {
        "id": "f-1MtHipzbIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# create a single conv2d layer\n",
        "conv_layer=nn.Conv2d(in_channels=3,\n",
        "                     out_channels=10,\n",
        "                     kernel_size=3,\n",
        "                     stride=1,\n",
        "                     padding=1)\n",
        "\n",
        "# pass the data through the convolutional layer\n",
        "conv_output = conv_layer(test_image)\n",
        "conv_output.shape"
      ],
      "metadata": {
        "id": "Q9RcNjylz8aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8bhxAELJ1XTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Stepping through nn.MaxPool2d()\n",
        "\n",
        "Documentation https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html"
      ],
      "metadata": {
        "id": "nWBEjX9INf9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out original iamge shape without unsqueezed simension\n",
        "print(f\"Test image original shape: {test_image.shape}\")\n",
        "print(f\"Test imagw with unsqueezed dimension: {test_image.unsqueeze(0).shape}\")\n",
        "\n",
        "# create a sample nn.MaxPool2d\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# pass data through just the conv_layer\n",
        "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
        "\n",
        "# pass data through the max pool layer\n",
        "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
        "print(f\"Shape after going through conv and maxpool(): {test_image_through_conv_and_max_pool.shape}\")"
      ],
      "metadata": {
        "id": "DA2vrQufNvzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# create a random tensor with a silimar number of dimensions to our images\n",
        "random_tensor = torch.randn(size=(1,1,2,2))\n",
        "print(f\"\\nRandom tensor: \\n {random_tensor}\")\n",
        "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
        "# create a maxpooling layer\n",
        "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "# pass the random tensor through the max pool layer\n",
        "max_pool_tensor = max_pool_layer(random_tensor)\n",
        "print(f\"\\nMax pool tensor: \\n {max_pool_tensor}\")\n",
        "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")\n"
      ],
      "metadata": {
        "id": "a7TFDFPHOyYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_image_tensor = torch.randn(size=(1,28,28))\n",
        "rand_image_tensor.shape"
      ],
      "metadata": {
        "id": "JgUFxbcOReK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(rand_image_tensor.unsqueeze(0).to(device))"
      ],
      "metadata": {
        "id": "tEzDCNgkTAoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Setup a loss function and optimizer for model 3\n"
      ],
      "metadata": {
        "id": "8yCe3-jBTX4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the loss funciton\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "AzFDYUpSWHBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Training and testing model_2 using our training and test fucntions\n"
      ],
      "metadata": {
        "id": "ok3wVSijWf3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2_gpu = timer()\n",
        "\n",
        "# train and test model\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  train_step(data_loader=train_dataloader,\n",
        "             model = model_2,\n",
        "             loss_fn= loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "  test_step(model=model_2,\n",
        "            loss_fn=loss_fn,\n",
        "            data_loader=test_dataloader,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device)\n",
        "\n",
        "train_time_end_model_2_gpu = timer()\n",
        "total_train_time_model_2_gpu  = print_train_time(end = train_time_end_model_2_gpu,\n",
        "                                                 start = train_time_start_model_2_gpu,\n",
        "                                                 device=device)\n",
        "\n"
      ],
      "metadata": {
        "id": "0BUITUMtWxy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = eval_model(\n",
        "    model=model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn,\n",
        "    device=device\n",
        ")\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "F6kPcP6-YKm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 8. Compare model results and training time.\n"
      ],
      "metadata": {
        "id": "6pMAWvfAd_Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results,\n",
        "                                model_1_results,\n",
        "                                model_2_results])\n",
        "compare_results"
      ],
      "metadata": {
        "id": "u1tQ4C4peQu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add training time to results comparison\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                    total_train_time_model_1,\n",
        "                                    total_train_time_model_2_gpu]\n",
        "\n",
        "compare_results"
      ],
      "metadata": {
        "id": "YrDsOI9TehCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize our model results\n",
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\")"
      ],
      "metadata": {
        "id": "ApbB6MQde5QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Make and evaluate random predictions with best model\n",
        "\n"
      ],
      "metadata": {
        "id": "JMugQ2DSfW5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # prepare the sample (add a batch dimension and pass to target device)\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "      # forward pass (mdoel output raw logits)\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      # get prediction prob logits->prediction prob\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "      # get pred_prob off the gpu for further calculations\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "  # stack the pred_probs to turn list into a tensor\n",
        "  return torch.stack(pred_probs)\n"
      ],
      "metadata": {
        "id": "W9btM-d4f6s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# random.seed(42)\n",
        "test_samples=[]\n",
        "test_labels=[]\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "# view the first sample shape\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "hezNgKGzhOKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[test_labels[0]])"
      ],
      "metadata": {
        "id": "X72bFsoehwR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                              data=test_samples)\n",
        "\n",
        "# view first two prediction probabilities\n",
        "pred_probs[:2]"
      ],
      "metadata": {
        "id": "nN2d4kGfh7xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to prediction prob to labels\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "y2HGqtvYiJw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "TjB0CLDKiXcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot predictions\n",
        "plt.figure(figsize=(9,9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # create subplot\n",
        "  plt.subplot(nrows,ncols,i+1)\n",
        "\n",
        "  # plot the target image\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  # find the prediction (in text form, e.g sandal)\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # get the truth label (in text form)\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # create a title for the plot\n",
        "  titel_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # check for equality between pred and truth and change color of title text\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(titel_text, fontsize=10, c=\"g\") # green text if prediction same as truth\n",
        "\n",
        "  else:\n",
        "    plt.title(titel_text, fontsize=10, c=\"r\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "nCvKC_nv0faK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Making a confusion matrix for further prediction evaluation\n",
        "\n",
        "Confustion matrix is a fantastic way of evaluating your classification models visually:\n",
        "https://lightning.ai/docs/torchmetrics/stable/classification/confusion_matrix.html\n",
        "\n",
        "1. Make predictions with our trained model on the test dataset\n",
        "2. Make a confusion matrix 'torchmetrics.ConfusionMatrix' https://docs.pytorch.org/ignite/generated/ignite.metrics.confusion_matrix.ConfusionMatrix.html\n",
        "3. Plot the confusion matrix using mixtend.plotting.plot_confusion_matrix()  \n",
        "https://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/"
      ],
      "metadata": {
        "id": "n1W-lpmW1rf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tqdm.audo\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. make predictions with trained model\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions...\"):\n",
        "    # send the data and targets to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # do the forward pass\n",
        "    y_logit = model_2(X)\n",
        "    # turn predictions from logits -> prediction probs -> prediction label\n",
        "    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
        "    # put prediction on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "# concatenate list of predictions into a tensor\n",
        "# print(y_preds)\n",
        "y_pred_tensor = torch.cat(y_preds)\n",
        "y_pred_tensor[:10]"
      ],
      "metadata": {
        "id": "1yARdr79ja7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_pred_tensor)"
      ],
      "metadata": {
        "id": "A_ns3lHOkf_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see if requried packages are installed and i fnot, install them..\n",
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "  assert int(mlxtend.__version__.split(\".\")[1] >= 19, \"mlxtend version should be 0.19.0 or higher\")\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "gVscu4fikqSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlxtend\n",
        "print(mlxtend.__version__)"
      ],
      "metadata": {
        "id": "v6QtWhnvnjhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. setup confusion instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(num_classes=len(class_names),\n",
        "                          task=\"multiclass\")\n",
        "confmat_tensor = confmat(preds = y_pred_tensor,\n",
        "                         target=test_data.targets)\n",
        "# 3. plot the confusion matrix\n",
        "fig, ax = plot_confusion_matrix(\n",
        "    conf_mat = confmat_tensor.numpy(), # matplotlib likes working with numpy\n",
        "    class_names=class_names,\n",
        "    figsize=(10,7)\n",
        ")"
      ],
      "metadata": {
        "id": "roA9OYqOks8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Save and reload your trained model"
      ],
      "metadata": {
        "id": "YNw_McBRn7Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# create model directory path\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "# create mdoel save\n",
        "MODEL_NAME = \"03_pytorch_computer_vision_mode_2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# save the mdoel state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "xjohyxK9osv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "# create a new instance\n",
        "torch.manual_seed(42)\n",
        "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                                     hidden_units=10,\n",
        "                                     output_shape=len(class_names))\n",
        "\n",
        "# load in the save state_dict()\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# send the model to the target device\n",
        "loaded_model_2.to(device)"
      ],
      "metadata": {
        "id": "h4P57FHdos7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "fEndGYY6qBQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate loaded model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(\n",
        "    model=loaded_model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "loaded_model_2_results"
      ],
      "metadata": {
        "id": "sW-cOwDOotDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if model results are close to each other\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "              torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
        "              atol=1e-02\n",
        ")"
      ],
      "metadata": {
        "id": "pJYtHoIaotLA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}